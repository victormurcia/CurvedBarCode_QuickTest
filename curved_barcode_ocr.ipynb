{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Curved Barcode OCR Pipeline\n\n**Goal:** Detect a barcode on a curved surface using `Piero2411/YOLOV8s-Barcode-Detection`,\nthen attempt to decode the text via two complementary paths:\n\n1. **Direct decode** — `zxingcpp` (structured barcode symbology, pure-Python, no system libs needed)\n2. **OCR fallback** — cylindrical unwrap → `EasyOCR` (when curvature distorts the symbology)\n\n```\ncurved_barcode.jpg\n       │\n       ▼\n  YOLOv8s detect          ← Piero2411/YOLOV8s-Barcode-Detection\n       │\n       ▼\n  Crop ROI + preprocess\n       │\n   ┌───┴────────────────┐\n   ▼                    ▼\nzxingcpp decode   Cylindrical unwrap\n   │                    │\n   ▼                    ▼\nbarcode string     EasyOCR text\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# One-time install — skip if you already have these\nimport subprocess, sys\n\npackages = [\n    \"ultralytics\",        # YOLOv8\n    \"huggingface_hub\",    # download model weights\n    \"opencv-python\",      # image processing\n    \"Pillow\",\n    \"numpy\",\n    \"matplotlib\",\n    \"scipy\",\n    \"scikit-image\",       # polar / cylindrical transforms\n    \"zxingcpp\",           # structured barcode decode (pure-Python, no system libs)\n    \"easyocr\",            # OCR fallback for curved text\n]\n\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *packages])\nprint(\"All packages installed.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom PIL import Image\nfrom huggingface_hub import hf_hub_download\nfrom ultralytics import YOLO\nimport zxingcpp\nimport easyocr\n\nIMAGE_PATH = Path(\"curved_barcode.jpg\")   # relative to notebook location\nHF_REPO    = \"Piero2411/YOLOV8s-Barcode-Detection\"\nMODEL_FILE = \"YOLOV8s_Barcode_Detection.pt\"\n\nprint(f\"Image exists: {IMAGE_PATH.exists()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Load & inspect the source image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread(str(IMAGE_PATH))\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "h, w = img_bgr.shape[:2]\n",
    "print(f\"Image size: {w} × {h} px  (width × height)\")\n",
    "\n",
    "plt.figure(figsize=(4, 6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Source: curved_barcode.jpg\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Download the YOLO model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=HF_REPO, filename=MODEL_FILE)\n",
    "print(f\"Model cached at: {model_path}\")\n",
    "\n",
    "yolo = YOLO(model_path)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  Run YOLO barcode detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = yolo.predict(\n",
    "    source=str(IMAGE_PATH),\n",
    "    imgsz=640,\n",
    "    conf=0.25,      # lower threshold — curved barcodes can look unusual\n",
    "    iou=0.45,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "result = results[0]\n",
    "boxes  = result.boxes\n",
    "\n",
    "print(f\"Detections: {len(boxes)}\")\n",
    "for i, box in enumerate(boxes):\n",
    "    x1, y1, x2, y2 = [int(v) for v in box.xyxy[0]]\n",
    "    conf  = float(box.conf[0])\n",
    "    cls   = int(box.cls[0])\n",
    "    label = result.names[cls]\n",
    "    print(f\"  [{i}] class={label}  conf={conf:.2f}  bbox=({x1},{y1})-({x2},{y2})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise detections\n",
    "annotated = result.plot()                          # returns BGR numpy array\n",
    "annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(4, 6))\n",
    "plt.imshow(annotated_rgb)\n",
    "plt.title(\"YOLO detections\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6  Crop the best detection (or full image as fallback)\n",
    "\n",
    "If YOLO finds a box we crop to it; otherwise we treat the whole image as the ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 10   # pixel padding around the crop\n",
    "\n",
    "if len(boxes) > 0:\n",
    "    # pick the detection with highest confidence\n",
    "    best_idx = int(boxes.conf.argmax())\n",
    "    x1, y1, x2, y2 = [int(v) for v in boxes[best_idx].xyxy[0]]\n",
    "    x1, y1 = max(0, x1 - PAD), max(0, y1 - PAD)\n",
    "    x2, y2 = min(w, x2 + PAD), min(h, y2 + PAD)\n",
    "    roi_bgr = img_bgr[y1:y2, x1:x2]\n",
    "    print(f\"Cropped to detection [{best_idx}]: ({x1},{y1}) → ({x2},{y2})\")\n",
    "else:\n",
    "    roi_bgr = img_bgr.copy()\n",
    "    print(\"No detection — using full image as ROI.\")\n",
    "\n",
    "roi_rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(3, 5))\n",
    "plt.imshow(roi_rgb)\n",
    "plt.title(\"ROI (cropped barcode)\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7  Path A — zxingcpp direct decode\n\n`zxingcpp` understands structured barcode symbologies (EAN, Code128, QR, DataMatrix, …).\nIt is a pure-Python binding to the ZXing-C++ library — no `libzbar` system package needed.\nOn a curved image it often fails — but it is fast, so we always try it first."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def try_zxing(img_bgr: np.ndarray) -> list[dict]:\n    \"\"\"Attempt zxingcpp decode on a BGR image; return list of result dicts.\"\"\"\n    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n    results = zxingcpp.read_barcodes(img_rgb)\n    return [\n        {\"type\": str(r.format), \"data\": r.text, \"position\": r.position}\n        for r in results\n        if r.valid\n    ]\n\nzxing_results = try_zxing(roi_bgr)\n\nif zxing_results:\n    print(\"zxingcpp decoded successfully:\")\n    for r in zxing_results:\n        print(f\"  type={r['type']}  data='{r['data']}'\")\nelse:\n    print(\"zxingcpp: no decode — curvature likely distorted the symbology. Continuing to OCR path.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8  Path B — Cylindrical / polar unwrap\n",
    "\n",
    "A barcode photographed on a curved surface (e.g. a can) follows a roughly\n",
    "**cylindrical projection**.  The key distortion is that the left/right columns\n",
    "of the barcode are \"compressed\" compared to the centre column.\n",
    "\n",
    "**Strategy:**\n",
    "1. Convert the ROI to grayscale and upscale for better resolution.\n",
    "2. Estimate the curvature by fitting a polynomial to the horizontal intensity\n",
    "   profile of the barcode lines.\n",
    "3. Apply a row-wise horizontal stretch (inverse cylindrical warp) to flatten it.\n",
    "4. Feed the rectified strip to EasyOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "\n",
    "def preprocess_roi(img_bgr: np.ndarray, scale: float = 2.0) -> np.ndarray:\n",
    "    \"\"\"Grayscale + upscale + CLAHE contrast enhancement.\"\"\"\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    if scale != 1.0:\n",
    "        nw = int(gray.shape[1] * scale)\n",
    "        nh = int(gray.shape[0] * scale)\n",
    "        gray = cv2.resize(gray, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    return clahe.apply(gray)\n",
    "\n",
    "\n",
    "def cylindrical_unwarp(gray: np.ndarray, strength: float = 0.4) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverse cylindrical warp.\n",
    "\n",
    "    Each row is treated as a horizontal cross-section of the cylinder.\n",
    "    Columns near the edges of the image are \"stretched\" to compensate for the\n",
    "    foreshortening caused by curvature.\n",
    "\n",
    "    strength ∈ [0, 1] — 0 = no correction, 1 = full hemisphere correction.\n",
    "    \"\"\"\n",
    "    h, w = gray.shape\n",
    "    cx = w / 2.0\n",
    "\n",
    "    # Map each output column x_out → source column x_src\n",
    "    # using the inverse of: x_out = cx + R * sin(θ),  x_src = cx + R * θ\n",
    "    # Approximation: x_src ≈ cx + (x_out - cx) * (1 - strength * ((x_out-cx)/cx)^2)\n",
    "    x_out = np.arange(w, dtype=np.float32)\n",
    "    norm  = (x_out - cx) / cx                          # [-1, 1]\n",
    "    x_src = cx + (x_out - cx) * (1.0 + strength * norm ** 2)\n",
    "    x_src = np.clip(x_src, 0, w - 1)\n",
    "\n",
    "    row_idx = np.tile(np.arange(h, dtype=np.float32).reshape(-1, 1), (1, w))\n",
    "    col_idx = np.tile(x_src, (h, 1))\n",
    "\n",
    "    unwarped = map_coordinates(gray, [row_idx, col_idx], order=1, mode=\"nearest\")\n",
    "    return unwarped.astype(np.uint8)\n",
    "\n",
    "\n",
    "# --- run it ---\n",
    "gray_roi   = preprocess_roi(roi_bgr, scale=2.0)\n",
    "unwarped   = cylindrical_unwarp(gray_roi, strength=0.4)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].imshow(gray_roi,  cmap=\"gray\"); axes[0].set_title(\"Preprocessed ROI\");  axes[0].axis(\"off\")\n",
    "axes[1].imshow(unwarped,  cmap=\"gray\"); axes[1].set_title(\"After cylindrical unwarp\"); axes[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 8b  Re-try zxingcpp on the unwarped image"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "unwarped_bgr = cv2.cvtColor(unwarped, cv2.COLOR_GRAY2BGR)\nzxing_unwarp_results = try_zxing(unwarped_bgr)\n\nif zxing_unwarp_results:\n    print(\"zxingcpp decoded the UNWARPED image:\")\n    for r in zxing_unwarp_results:\n        print(f\"  type={r['type']}  data='{r['data']}'\")\nelse:\n    print(\"zxingcpp still could not decode — proceeding to EasyOCR.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9  Path B (continued) — EasyOCR on the unwarped strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise EasyOCR reader (downloads models on first run, ~100 MB)\n",
    "reader = easyocr.Reader([\"en\"], gpu=False)\n",
    "print(\"EasyOCR reader ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_easyocr(gray_img: np.ndarray, reader) -> list[dict]:\n",
    "    \"\"\"Run EasyOCR and return list of {text, conf, bbox} dicts.\"\"\"\n",
    "    ocr_results = reader.readtext(gray_img, detail=1, paragraph=False)\n",
    "    return [\n",
    "        {\"text\": text, \"conf\": conf, \"bbox\": bbox}\n",
    "        for bbox, text, conf in ocr_results\n",
    "    ]\n",
    "\n",
    "\n",
    "ocr_on_unwarped = run_easyocr(unwarped, reader)\n",
    "\n",
    "print(f\"EasyOCR found {len(ocr_on_unwarped)} text region(s) on unwarped image:\")\n",
    "for r in ocr_on_unwarped:\n",
    "    print(f\"  conf={r['conf']:.2f}  text='{r['text']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also try directly on the original (non-unwarped) grayscale for comparison\n",
    "gray_direct = preprocess_roi(roi_bgr, scale=2.0)\n",
    "ocr_on_direct = run_easyocr(gray_direct, reader)\n",
    "\n",
    "print(f\"EasyOCR found {len(ocr_on_direct)} text region(s) on preprocessed-only image:\")\n",
    "for r in ocr_on_direct:\n",
    "    print(f\"  conf={r['conf']:.2f}  text='{r['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10  Visualise OCR results on the unwarped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ocr_results(gray_img: np.ndarray, ocr_results: list[dict]) -> np.ndarray:\n",
    "    \"\"\"Draw bounding boxes and labels onto a copy of the image.\"\"\"\n",
    "    vis = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)\n",
    "    for r in ocr_results:\n",
    "        pts = np.array(r[\"bbox\"], dtype=np.int32)\n",
    "        cv2.polylines(vis, [pts], isClosed=True, color=(255, 80, 0), thickness=2)\n",
    "        org = tuple(pts[0])\n",
    "        cv2.putText(vis, r[\"text\"], org, cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (255, 80, 0), 2, cv2.LINE_AA)\n",
    "    return vis\n",
    "\n",
    "\n",
    "vis_unwarped = draw_ocr_results(unwarped, ocr_on_unwarped)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(unwarped, cmap=\"gray\")\n",
    "axes[0].set_title(\"Unwarped (input to EasyOCR)\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(vis_unwarped)\n",
    "axes[1].set_title(\"EasyOCR detections\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11  Aggregate & rank results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"═\" * 55)\nprint(\" FINAL RESULTS SUMMARY\")\nprint(\"═\" * 55)\n\nall_candidates = []\n\nfor r in zxing_results:\n    all_candidates.append({\"source\": \"zxingcpp (original)\",  \"text\": r[\"data\"], \"conf\": 1.0, \"type\": r[\"type\"]})\n\nfor r in zxing_unwarp_results:\n    all_candidates.append({\"source\": \"zxingcpp (unwarped)\",  \"text\": r[\"data\"], \"conf\": 1.0, \"type\": r[\"type\"]})\n\nfor r in ocr_on_unwarped:\n    all_candidates.append({\"source\": \"EasyOCR (unwarped)\",   \"text\": r[\"text\"], \"conf\": r[\"conf\"], \"type\": \"OCR\"})\n\nfor r in ocr_on_direct:\n    all_candidates.append({\"source\": \"EasyOCR (direct)\",     \"text\": r[\"text\"], \"conf\": r[\"conf\"], \"type\": \"OCR\"})\n\nif all_candidates:\n    all_candidates.sort(key=lambda x: x[\"conf\"], reverse=True)\n    print(f\"{'Source':<28} {'Type':<10} {'Conf':>5}  Text\")\n    print(\"-\" * 55)\n    for c in all_candidates:\n        print(f\"{c['source']:<28} {c['type']:<10} {c['conf']:>5.2f}  {c['text']}\")\n    print()\n    best = all_candidates[0]\n    print(f\"Best candidate  →  '{best['text']}'  (source: {best['source']}, conf={best['conf']:.2f})\")\nelse:\n    print(\"No text could be extracted.\")\n    print(\"Possible next steps:\")\n    print(\"  • Increase image resolution / lighting\")\n    print(\"  • Tune cylindrical_unwarp strength parameter\")\n    print(\"  • Try a dedicated curved-text detector (e.g. ABCNet, TextBPN)\")\n\nprint(\"═\" * 55)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12  Tuning guide\n\n| Parameter | Where | Effect |\n|---|---|---|\n| `conf=` in `yolo.predict` | §5 | Lower → more detections, higher false-positive rate |\n| `scale=` in `preprocess_roi` | §8 | Higher → finer OCR, slower |\n| `strength=` in `cylindrical_unwarp` | §8 | Match to the curvature radius of your container |\n| `gpu=False` in `easyocr.Reader` | §9 | Switch to `True` if a CUDA GPU is available |\n\n### Possible upgrades for production\n\n* **Better rectification** — fit an actual cylinder model using the vanishing lines of the barcode bars (RANSAC + homography).\n* **Curved-text OCR models** — ABCNet v2, TextBPN, or TESTR are specifically designed for curved/arbitrary-shape text.\n* **Richer symbology support** — `zxingcpp` already covers EAN, Code128, QR, DataMatrix, PDF417, and more out of the box.\n* **Data augmentation** — fine-tune the YOLO model with more examples of wrapped/curved barcodes if detection confidence is low."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}